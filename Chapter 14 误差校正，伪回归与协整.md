# **Chapter 14 误差校正，伪回归与协整**

## **自回归分布滞后模型的误差校正形式**

14.1最简单的ARDL（自回归分布滞后）模型是ARDL（1，1）：

$y_t=\beta_0+\phi y_{t-1}+\beta_{1,0}x_t+\beta_{1,1}x_{t-1}+a_t$(14.1)

现在假设我们通过将其重写为

$\triangledown y_t=\beta_0-(1-\phi)y_{t-1}+(\beta_{1,0}+\beta_{1,1})x_{t-1}+\beta_{1,0}\triangledown x_t+a_t$

或

$\triangledown y_t=\beta_{1,0}\triangledown x_t-(1-\phi)(y_{t-1}-\frac{\beta_0}{1-\phi}-\frac{\beta_{1,0}+\beta_{1,1}}{1-\phi}x_{t-1})+a_t$

即，为

$\triangledown y_t=\beta_{1,0}\triangledown x_t-(1-\phi)(y_{t-1}-\theta_0-\theta_1x_{t-1})+a_t$(14.2)

ARDL的这种表示方式表示了内生变量$\triangledown y_t$的当前变化，作为外生变量$\triangledown x_t$当前变化的线性函数和长期“平衡”关系$y=\theta_0+\theta_1x$的先前差异（或误差）的$1-\phi$比例。表示（14.2）被称为误差校正模型（error-correction model）或ECM。如果平衡关系的参数未知，则可以估计通过在（14.2）上使用非线性最小二乘法或将ECM表示为

$\triangledown y_t=\beta_0+\beta_{1,0}\triangledown x_t+\gamma(y_{t-1}-x_{t-1})+\delta x_{t-1}+a_t$(14.3)

可以由OLS直接估计，并且比较（14.3）和（14.2）显示，

$\theta_0=-\frac{\beta_0}{\gamma},\theta_1=\frac{\gamma-\delta}{\gamma}$

ECM最初是由Sargan（1964）提出，后来又被Davidson等人（1978）引入。它可以很容易地扩展到一般的模型。将纠错表示为

$ec_t=y_t-\theta_0-\sum_{j=0}^M\theta_j x_{j,t}$

然后（14.2）推广为

$\triangledown y_t=\beta_0-\phi(1)ec_{t-1}+\phi^*(B)\triangledown y_{t-1}+  \sum_{j=1}^M\widetilde\beta_j(B)\triangledown x_{j,t-1}+  \sum_{j=1}^M\beta_j(B)\triangledown x_{j,t}+a_t$(14.4)

其中

$\phi^*(B)=\sum_{i=1}^p\phi_iB^i=\phi(B)-1$



## **伪回归**

14.2  已含蓄假定所有输入ARDL /ECM的变量是平稳的，因此任何非平稳序列事先已经适当地加以区别。如果非平稳变量没有先验差异，而是作为水平输入会发生什么？这是一个显而易见的理论问题。OLS一致性的标准证明，当存在随机回归项时，取决于假设$T^{-1}\mathbf X'\mathbf X$的概率极限趋于固定矩阵，其中$\mathbf X$是包含解释变量数据的矩阵；即，平方和期望的矩阵和数据的向量积倾向于一个常数矩阵。换句话说，随着样本量T的增加，数据的样本矩按总体值安定。为了样本矩收敛到固定总体矩，数据必须平稳。如果不是，那么，比如在单积序列的情况下，数据可能出现随时间增加幅度的趋势，因此平方和期望的矩阵和数据的向量积没有固定值。



14.3 但是，非平稳时间序列回归的实际含义是什么？这是由Granger和Newbold（1974）考虑的问题，开始时将注意力集中，接着在报告高度拟合时间序列的应用计量经济学文献中广泛实践，由复相关系数$R^2$测量，伴随着极低的检验自相关误差的Durbin和Watson（1950，1951）dw统计量的值。在白噪声误差的零假设下，dw=2，而在正自相关误差的备择假设下，dw\<2，在极限情况下，当误差遵循随机游动时，dw=0。因此，如果dw统计量很小，则残差肯定存在相当大程度的正自相关，以非平稳性为边界。



14.4 Granger和Newbold考虑以下数据生成过程（DGP）：

$y_t=\phi y_{t-1}+u_t,u_t\sim i.i.d.(0,\sigma_u^2)$(14.5a)

$x_t=\phi^* x_{t-1}+v_t,v_t\sim i.i.d.(0,\sigma_v^2)$(14.5b)

$E(u_tv_s)=0$,对所有t，s

$E(u_tu_{t-k})=E(v_tv_{t-k})=0,k\ne0$

即$y_t$和$x_t$是不相关的一阶自回归过程。既然$x_t$既不影响也不受$y_t$的影响，应该希望在回归模型

$y_t=\beta_0+\beta_1x_t+\varepsilon_t$(14.6)

系数$\beta_1$会以概率收敛到零，反映出两个序列之间缺乏任何关系，$R^2$统计量也会从该回归中得出。



14.5  在（14.6）中,原假设$\beta_1=0$，意味着$y_t=\beta_0+\varepsilon_t$和备择假设$\beta_1\ne0$都将导致错误的模型，因为（14.5）给出的真实DGP不嵌套在（14.6）中。例如，原假设$\beta_1=0$意味着$y_t$是OLS回归假设下的白噪声，仅且仅当$\phi=0$时。但是，如果$y_t$和$x_t$是平稳的自相关过程（$-1<\phi,\phi^*<1$），则OLS-估计回归系数$\hat\beta_1$和其关联的t-统计量($t=|\hat\beta_1|/se(\hat\beta_1)$)都将收敛于零，当$T\to\infty$，尽管t检验会过高拒绝，即对平稳序列，与“因变量”无关的一组变量的回归产生的系数收敛到零。

但是，在有限的样本中，仍然存在问题。 Granger和Newbold表示，如果$\phi$和$\phi^*$都很大，比如在0.9的范围内，那么$R^2$的期望值将在0.5左右，这意味着该统计量的合理的高值不应被视为自相关序列之间有显著关系的证据。通常，$R^2$的高值也将伴随着较低的dw值，因此Granger和Newbold认为不等式$R^2>dw$很可能来自尝试拟合独立但自相关的时间序列的水平相关的回归。



14.6如果回归拟合为独立随机游动，即在等式 （14.5a，b）$\phi=\phi^*=1$，则会出现更严重的问题。图14.1 面板（A）所示$t=|\hat\beta_1|/se(\hat\beta_1)$的频率分布直方图，来自1000次模拟一对独立随机游动的回归，每个长度为T=50，起始值为$y_0=x_0=0$，每个有标准正态新息。面板（B）显示了$R^2$统计量的频率分布直方图，而面板（C）显示dw统计量的频率分布直方图。

使用传统的5％显著水平的t检验（因此t临界值约为2），（正确）零假设为两个序列没有关系（$\beta_1=0$）三分之二将被错误地拒绝（每1000中有670次）。如果$\hat\beta_1/se(\hat\beta_1)$作为标准正态，则t的期望值可能显示为$\sqrt{22}/\pi=0.8$，但是图4.1中t统计量的平均值为3.90，这表明$\hat\beta_1$的标准偏差被大约5倍低估。因此，代替使用临界t值2，应该使用超过10的值，在确定估计系数在5％的水平上是否显著时（实际上，有60个t统计量大于10）。

$R^2$的平均值为0.24，几乎为三分之二（每1000中有626次）的值大于0.2。dw统计的平均值是0.33，最大值为1.16，甚至比1％临界值1.32还低，因此该统计量会在1000个回归中的每个中标记出残差自相关问题，正如我们希望的。几乎三分之一的回归中（每1000中有322次）不等式$R^2>dw$成立。

```python
import numpy as np
import random
import matplotlib.pyplot as plt 
import statsmodels.api as sm
from statsmodels.stats.stattools import durbin_watson
#模拟的随机游动
random.seed(50)
t = []
r = []
dw = []
count = 0
for i in range(1000):
    x = [0]
    y = [0]
    for i in range(1, 50):
        n1 = random.gauss(0, 1)
        r1 = x[i - 1] + n1
        n2 = random.gauss(0, 1)
        r2 = y[i - 1] + n2
        x.append(r1)
        y.append(r2)

    X = sm.add_constant(x)
    ls = sm.OLS(y, X).fit()
    t.append(abs(ls.tvalues[1]))
    r.append(ls.rsquared)
    dw.append(durbin_watson(ls.resid))
    if ls.rsquared > durbin_watson(ls.resid):
        count += 1
    
plt.hist(t,bins=9,range=(0,18),rwidth=0.8)
plt.hist(r,bins=10,range=(0,1),rwidth=0.8)
plt.hist(dw,bins=6,range=(0,1.2),rwidth=0.8)
```

![a](media/a.png)

(A)$t=|\hat\beta_1|/se(\hat\beta_1)$的频率分布直方图

![b](media/b.png)

(B)$R^2$统计量的频率分布直方图

![](media/c.png)

(C)dw统计量的频率分布直方图

图14.1 通过1000次模拟一对独立随机游动的回归得到的统计量频率分布直方图



14.7在进一步的模拟中，Granger和Newbold将DGP扩展到包括多个回归变量和ARIMA（0,1,1）新息，发现重复图14.1的结果。确实，随着独立的随机游走的数量增加，没有任何关系的零假设在常规显著水平上被拒绝的倍数也增加了。Granger和Newbold认为，使用单积时间序列进行的回归可能是虚假的，因为它们通常会产生明显的显著关系，即使变量互不相关。



14.8这些基本的经验结论Phillips（1986）给出了分析基础。使用DGP （14.5a，b），但更通用假设关于新息$u_t$和$v_t$（本质上是5.12弱依赖条件），菲利普斯表明$\hat\beta_0$和$\hat\beta_1$都不以概率收敛到常数，当$T\to\infty$。此外，$\hat\beta_1$有一个非退化的极限分布，因此不同的任意大样本将产生随机不同的$\beta_1$估计值。$\hat\beta_0$的分布事实上发散，因此估计可能会随着样本量的增加而越来越偏离真实值。回归（14.6）的不确定性起源于其虚假性质，渐近导致$y_t$和$x_t$的样本矩（及其联合样本矩）不收敛于常数，但经过适当标准化，收敛到随机变量。



14.9  Phillips然后表明，$\hat\beta_1$上常规t比率（类似地对$\hat\beta_0$）不具有t分布：事实上因为发散，它不具有任何极限分布，所以这些检验没有渐近正确的值。这些检验使用临界值时的拒绝率由传统渐近理论（如1.96）给出，继续随着样本量的增加而增加。

$R^2$统计量具有非退化的极限分布,dw趋于零，当$T\to\infty$。此统计量的低值和$R^2$的中等值，因此，在伪回归中可以预期到，比如(14.6)，用类似单积过程生成的数据。



14.10实际上，Yule（1926）对伪回归或无意义回归的进行早期分析是在 Granger 和 Newbold之前近半个世纪。Yule还使用了模拟，但专注于相关的分布，而不是回归，系数。他的分析仍然值得注意，考虑了三种情况：（1）两个变量均为$I(0)$及i.i.d.（2）两个变量均为$I(1)$，其差分为iid；和（3）两个变量均为$I(2)$，其二阶差分为i.i.d.。

图14.2‑14.4表示长度为T=100的一对变量的1000次模拟的相关系数分布。案例（1）显示在图14.2，给出两个独立的标准正态白噪声$u_t$和$v_t$之间相关系数$r_{uv}$的分布。这个相关关系表现良好，是对称的，接近高斯，分布以零为中心，以$\pm1$为边界。案例（2）如图14.3所示。这里相关系数为$r_{yx}$，其中$y_t=y_{t-1}+u_t$和$x_t=x_{t-1}+v_t$为独立的随机游走。$r_{yx}$的分布更接近半椭圆，在分布的两端都有额外的频率。因此，$r_{yx}$的值与情况（1）相比，远离零的可能性更大。图14.4显示案例（3）$r_{zw}$相关关系，其中$z_t=z_{t-1}+y_t=2z_{t-1}-z_{t-2}+u_t$和$w_t=w_{t-1}+x_t=2w_{t-1}-w_{t-2}+v_t$。$r_{zw}$的分布为U形，因此两个$I(2)$不相关的序列最可能的相关关系是$\pm1$，如果两个序列完全相关，则恰好是这个值。

```python
import numpy as np
import random
import matplotlib.pyplot as plt 
#两个独立I(0)序列之间的相关系数的频率分布
random.seed(50)
c = []
for i in range(1000):
    u = [random.gauss(0, 1) for i in range(100)]
    v = [random.gauss(0, 1) for i in range(100)]
    c.append(np.corrcoef(u,v)[0][1])
    
plt.hist(c,rwidth=0.8)
```

![2](media/2.png)

图14.2两个独立$I(0)$序列之间的相关系数的频率分布

```python
#两个有独立一阶差分I(1)序列之间相关系数的频率分布
random.seed(50)
c = []
for i in range(1000):
    x = [random.gauss(0, 1)]
    y = [random.gauss(0, 1)]
    for i in range(1, 100):
        n1 = random.gauss(0, 1)
        r1 = x[i - 1] + n1
        n2 = random.gauss(0, 1)
        r2 = y[i - 1] + n2
        x.append(r1)
        y.append(r2)
    c.append(np.corrcoef(x,y)[0][1])
plt.hist(c,rwidth=0.8)
```

![](media/3.png)

图14.3两个有独立一阶差分$I(1)$序列之间相关系数的频率分布

14.11如果基于相关系数的检验统计量，假设分布是应用到情况（1）的那个，事实上，正确分布是一种适用于情况（2）的分布，独立零假设被否决的频率将大大超过检验大小名义值，由如果（1）是真的预期的拒绝次数给出。情况（3）甚至更糟，结果是真相的可能性最小，因为几乎没有机会找到，尽管预期在零假设下的总体期望为零。确实，最可能的样本值为。

```python
#两个有独立一阶差分I(2)序列之间相关系数的频率分布
random.seed(50)
c = []
for i in range(1000):
    x0 = random.gauss(0, 1)
    y0 = random.gauss(0, 1)
    x = [x0,2*x0+random.gauss(0, 1)]
    y = [y0,2*y0+random.gauss(0, 1)]
    for i in range(2, 100):
        n1 = random.gauss(0, 1)
        r1 = 2*x[i-1] - x[i-2] + n1
        n2 = random.gauss(0, 1)
        r2 = 2*y[i-1] - y[i-2] + n2
        x.append(r1)
        y.append(r2)
    c.append(np.corrcoef(x,y)[0][1])
plt.hist(c,rwidth=0.8)
```

![](media/4.png)

图14.4两个有独立二阶差分$I(2)$序列之间相关系数的频率分布



14.12 图 14.2‑14.4因此显示出由伪相关产生的推理困难，通过回归相同单积阶数的独立序列。难点还出现在$I(2)$在$I(1)$序列上的回归（反之亦然），图14.5显示了$r_{zx}$的分布也为U形。

不太严重的问题发生在$I(1)$在$I(0)$序列上的回归（反之亦然）。如图14.6所示，$r_{yv}$的分布形状类似$r_{uv}$。原因是当$I(0)$序列在$I(1)$序列上回归时，OLS使回归一致和最小化平方和的唯一方法是是使$I(1)$变量的系数（相当于相关性）为零。当两个系列都单积时，没有这种可能性。

```python
#分别具有独立一、二阶差分的I(1)序列和I(2)序列之间的相关系数的频率分布
random.seed(50)
c = []
for i in range(1000):
    x0 = random.gauss(0, 1)
    x = [x0,2*x0+random.gauss(0, 1)]
    y = [0]
    for i in range(2, 100):
        n1 = random.gauss(0, 1)
        r1 = 2*x[i-1] - x[i-2] + n1
        x.append(r1)    
    for i in range(1, 100):
        n2 = random.gauss(0, 1)
        r2 = y[i - 1] + n2
        y.append(r2)
    c.append(np.corrcoef(x,y)[0][1])
plt.hist(c,rwidth=0.8)
```

![](media/5.png)

图14.5分别具有独立一、二阶差分的$I(1)$序列和$I(2)$序列之间的相关系数的频率分布

```python
#I(0)序列和具有独立一阶差分I(1)序列之间的相关系数的频率分布
random.seed(50)
c = []

for i in range(1000):
    x = [random.gauss(0, 1) for i in range(100)]
    y = [0]   
    for i in range(1, 100):
        n2 = random.gauss(0, 1)
        r2 = y[i - 1] + n2
        y.append(r2)
    c.append(np.corrcoef(x,y)[0][1])
plt.hist(c,rwidth=0.8)
```

![](media/6.png)

图14.6 $I(0)$序列和具有独立一阶差分$I(1)$序列之间的相关系数的频率分布



14.13与非平稳回归项相关的伪回归问题是否可以通过在回归中包含时间趋势来缓解？即通过将（14.6）替换为

$y_t=\beta_0+\beta_1x_t+\theta t+\varepsilon_t$(14.7)

这样看来不行，因为$\hat\beta_1$继续有非退化渐近分布（即，它不收敛于零），检验$\beta_1=0$在分布上发散，倾向于导致对该零假设的错误拒绝（这些结果由Durlauf和Phillips提供，1988年）。因此，伪回归问题无法通过尝试从数据中删除确定性趋势解决。



14.14那么，应采取什么措施解决虚假回归问题？经过进一步的扩展模拟分析后，Granger和Newbold（1977年）推荐适当差分非平稳回归项。虽然他们不认为这是“通用确保解决方案”，他们确实认为当非平稳序列平滑，有大和正的低阶自相关时，差分有用，换句话说，几乎是随机游走。



## 误差校正和协整

14.16表 示（14.6）的伪性质的一种等效方法是注意，误差$\varepsilon_t=y_t-\beta_0-\beta_1x_t$可能在DGP（14.5）下，被视为$I(1)$过程的线性组合，因此应为$I(1)$，因此使所有最小二乘回归理论无效。虽然从表面上看，这将是一个非常明智的论点，事实并非总是如此，因为可能$I(1)$过程的线性组合实际上是$I(0)$。



14.17更一般而言，如果$y_t\sim I(d)$和$x_t\sim I(d)$，则线性组合

$e_t=y_t-ax_t$(14.8)

通常也会是$I(d)$。然而$e_t$可能被更低阶单积，例如$I(d-b)$，其中b\>0，在这种情况下有特殊约束在两个序列的长期分量上。如果d=b=1，$y_t$和$x_t$均为$I(1)$，因此以“永久”分量为主导，$e_t$将是$I(0)$，因此，将仅具有瞬时分量，因此，$y_t$和$ax_t$必须具有长期分量抵消来产生$e_t$。在这种情况下，可以说$y_t$和$x_t$是协整的，尽管必须强调的是，通常不会真的存在一个a使$e_t\sim I(0)$或一般地，$I(d-b)$。



14.18协整的概念可能与长期均衡的概念相关（回想14.1），可以通过双变量关系$y_t=ax_t$来说明，或

$y_t-ax_t=0$

因此，（14.8）的$e_t$衡量了“系统”在多大程度上失衡，可以被称为“平衡误差”。假设d=b=1，使得$y_t$和$x_t$均为$I(1)$，则平衡误差为$I(0)$，且$e_t$很少会漂移远离零并且经常会穿过零线。换句话说，平衡有时会发生，至少接近一个近似值，而如果$y_t$和$x_t$不协整，则$e_t\sim I(1)$，平衡误差将广泛漂移并很少穿过零线，这表明在这种情况下，平衡的概念没有实际意义。



14.19 可否将协整概念与伪回归分析联系起来？再考虑（14.5），但是现在放宽独立条件，即让$E(u_tv_t)=\sigma_{uv}$，定义（同期）新息协方差矩阵

$\mathbf\Sigma=\left[\begin{array}{}\sigma_u^2 & \sigma_{uv}\\\sigma_{uv} &\sigma_v^2\end{array}\right]$

最小二乘理论适用于（14.6），我们要求$\mathbf\Sigma$非奇异。但是，如果它是奇异的，则

$|\mathbf\Sigma|=\sigma_u^2\sigma_v^2-\sigma_{uv}^2=0$

这意味着$\mathbf\Sigma(1-a)=0$，其中$a=\sigma_{uv}/\sigma_v^2$。$\mathbf\Sigma$奇异成为$y_t$和$x_t$协整的必要条件，既然$|\mathbf\Sigma|=0$表示新息$u_t$和$v_t$之间的“长期”相关性，由$\rho_{uv}=\sigma_{uv}/\sigma_u\sigma_v$给出，是1（Phillips，1986）。对于$\rho_{uv}<1$，$y_t$和$x_t$不协整,并且当$\rho_{uv}=0$，$u_t$和$v_t$是独立的，我们有Granger和Newbold的伪回归。



14.20协整和误差修正也紧密相连。平衡误差（14.8）为$I(1)$，如果$y_t$和$x_t$均为$I(1)$且协整，恰好是在（14.4）ECM中$ec_t$带有滞后的形式。因此，如果$y_t$和$x_{1,t},x_{2,t},...,x_{M,t}$都是$I(1)$，且如果协整，则

$e_t=y_t-a_1x_{1,t}-...-a_Mx_{M,t}\sim I(0)$

那么将存在（14.4）形式的ECM ，其结果称为Granger表示定理。



14.21当$y_t$和$x_t$之间存在协整时，则该协整回归（14.6）具有一些有趣的特性。如果$x_t$不包含漂移则$\beta_1$的OLS估计是超一致的，$\hat\beta_1$收敛到$\beta_1$以速率T而不是$T^{1/2}$，如在标准回归情况下。因此，OLS将精确估计协整参数。然而，$\hat\beta_1$的分布将是偏斜的，相关的t比率不会渐近正态。

不包含漂移的假设并非无害，因为如果它确实含有一个漂移则$\hat\beta_1$的分布恢复正态。有趣的是，如果存在一组回归变量$x_{1,t},x_{2,t},...,x_{M,t}$;其中一些可能会有漂移，则协整参数的超一致性继续保持，但估计量的有限联合分布既是非正态的又是奇异的，因为回归项将渐近完全修正。这是因为带有漂移的$I(1)$变量始终可以表示为时间趋势和无漂移的$I(1)$变量的总和，如

$\triangledown x_t=\pi+v_t=x_0+\pi t+\triangledown \widetilde x_t,\triangledown \widetilde x_t=v_t$

因此这样两个变量之间的相关性将由它们的趋势决定，而不是无漂移的$I(1)$分量，且将渐近为1。



## 检验协整

14.22 鉴于协整在使用单积变量的回归模型中起着至关重要的作用，检验其存在显然很重要。检验可以基于协整回归的残差，即

$\hat e_t=y_t-\hat\beta_0-\hat\beta_1x_{1,t}-...-\hat\beta_Mx_{M,t}$(14.9)

这种基于残差程序试图检验没有协整的零假设，通过对$\hat e_t$的单位根检验（参阅Engle和Granger，1987年：这些检验统计量用EG表示，以区别于常规的Dickey‑Fuller检验）。

这里的问题是，由于$\hat e_t$是从估计协整参数的回归中作为残差得出的，如果非协整零假设是真的，协整参数估计将无法识别，使用常规$\tau_{\mu}$临界值将过于频繁拒绝零假设，因为OLS将寻求一组协整参数，最小化残差方差，因此，最有可能导致平稳的残差序列。

影响临界值的另一个因素是回归项的数量M。例如，大T 5％的$\tau_{\mu}$临界值当M=1是-3.37，而如果M=5为-4.71（通常5％临界值是-2.86）。与常规的单元根检验一样，可用不同临界值集合，如果协整回归中没有常数，或者如果同时存在常数和趋势。



14.23当然，所有出现在协整回归（14.9）中的变量都必须为$I(1)$，因此此假设需要检查，将M+1个变量用于单元根的预检验。这些检验显然有潜力误导,当对单积属性进行分类时。Pesaran等（2001年，此后PSS）则提出了基于ARDL模型的协整“边界”检验，对变量是$I(0)$，$I(1)$还是相互协整都稳健。ARDL模型的条件误差校正（CEC）形式具有时间趋势，

$\triangledown y_t=\alpha_0+\alpha_1t-\phi(1)y_{t-1}+\sum_{j=1}^M\beta_j(1)x_{j,t-1}+\phi^*(B)\triangledown y_{t-1}+\sum_{j=0}^M\gamma_j(B)\triangledown x_{j,t}+a_t$(14.10)

其中$\gamma_j(B)=\beta_j(1)+\widetilde \beta_j(B)$。没有长期关系（无协整）的零假设为，$\phi(1)=\beta_1(1)=...=\beta_M(1)=0$，其可以使用标准F或Wald统计量检验。PSS提供两组渐近临界值，对应极端情况，所有变量的值是$I(0)$或纯$I(1)$。当检验统计量低于下临界值时，不拒绝零假设，并且得出结论认为不可能协整。如果检验统计量高于上临界值，可以拒绝零假设，并且可以得出结论，协整是可能的。但是，如果检验统计量落在上下临界值之间，检验不确定，需要其他分析和检验。



## **估计协整回归**

14.25 已经发现$y_t$与$x_{1,t},...,x_{M,t}$协整，在协整回归中

$y_t=\beta_0+\beta_1x_{1,t}+...+\beta_Mx_{M,t}+e_t$(14.11)

需要估计参数。尽管OLS估计会得到参数的超一致估计，尽管如此，它们还是有偏差和不对称的采样分布，甚至渐近。这是$y_t$与$x_{j,t}$之间潜在同时性的结果，以及$e_t$的自相关性，这是特有的，假设误差只要求为$I(0)$而不是白噪声。OLS估计和伴随标准误差，因此，为形成关于协整参数推断提供了不可靠的基础。

Phillips和Hansen（1990年）完全修改的OLS（FM-OLS）估计，对OLS引入了半参数校正，从而消除了这种偏差和不对称。另一方面，动态OLS（DOLS），通过把$\triangledown x_{j,t}$的提前和滞后，以及可能的$\triangledown y_t$滞后，作为（14.10）中的附加回归变量，因此标准OLS可以继续使用，即

$y_t=\beta_0+\sum_{j=1}^M\beta_{j,t}x_{j,t}+\sum_{i=1}^p\gamma_i\triangledown y_{t-i}+\sum_{j=1}^M\sum_{i=-p_1}^{p_2}\delta_{j,i}\triangledown x_{j,t-i}+e_t$(14.12)

14.23中的CEC适当形式的误差更正项还提供了对协整关系的估计：例如，如果在CEC（14.10）没有截距或趋势，则

$ec_t=y_t-\sum_{j=1}^M\frac{\beta_j(1)}{\phi(1)}x_{j,t}$

将提供对协整参数的估计。

